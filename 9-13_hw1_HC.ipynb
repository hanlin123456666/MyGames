{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b9cf054-2ec2-47ef-8b25-afc7bb01afea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DS 5220 - AI-Assisted Programming in Python\n",
    "> Homework 1: Python Review\n",
    "\n",
    "**Due: Wednesday, September 13 at 11:59pm**\n",
    "\n",
    "## Instructions\n",
    "This homework is designed to assess your Python skills and your understanding of how these skills apply to data science problems. Each question generally includes multiple parts:\n",
    "\n",
    "* **Part A**: Solve the problem using basic Python data structures.  \n",
    "* **Part B**: Solve the problem using pandas.  \n",
    "* **Part C**: Reflect on the solutions, considering its design aspects, applicability, usability, maintainability, readability, etc. \n",
    "* **Part D**: Generate an alternative approach to the problem using a generative AI tool. Describe or copy/paste this approach and describe pros/cons of their approach relative to yours. If you need help thinking through the pros/cons, you can directly ask the generative AI about differences between your code/its code.\n",
    "\n",
    "## Use of Generative AI\n",
    "First, try letters A, B, and C of each question on your own, with no assistance from generative AI. If needed, you can _**then**_ use generative AI on these items _**but only as a tutor, and it should not directly tell you the answer. It should guide you on a journey for you to find the answer**._ Part D of each question explicitly requires generative AI. \n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6736bcdc-0111-4a78-8ad2-e9ac318db63e",
   "metadata": {},
   "source": [
    "## Problem 1: Data Cleaning\n",
    "\n",
    "* **Part A**: You have a list of dictionaries, each representing a data record with name, age, and email. Write a function that takes this list and returns a new list where:\n",
    "\n",
    "  * Records with an invalid age (non-numeric or outside the range of 0-120) or missing email are removed.\n",
    "  * Names are standardized to have the first letter capitalized.\n",
    "\n",
    "* **Part B**: Convert the list of dictionaries to a pandas DataFrame and perform the same operation using pandas functions.\n",
    "\n",
    "* **Part C**: How would you extend this functionality to validate email formats as well?\n",
    "\n",
    "* **Part D**: (Follow the general Part D instructions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c977a1f8-ad7e-4e78-ae4a-8a5434f5fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic dataset\n",
    "sample_data = [\n",
    "    {\"name\": \"alice\", \"age\": 30, \"email\": \"alice@email.com\"},\n",
    "    {\"name\": \"bob\", \"age\": \"not_an_age\", \"email\": \"bob@email.com\"},\n",
    "    {\"name\": \"carol\", \"age\": 150, \"email\": \"\"},\n",
    "    {\"name\": \"dave\", \"age\": 40, \"email\": \"dave@email.com\"}\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4d26b6a-889e-4975-959f-bf273d03df67",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d1dd0fe-02ec-43f7-ab02-9c0f40e067ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Alice', 'age': 30, 'email': 'alice@email.com'}, {'name': 'Dave', 'age': 40, 'email': 'dave@email.com'}]\n"
     ]
    }
   ],
   "source": [
    "# Your answers\n",
    "valid_data = []\n",
    "for x in sample_data:\n",
    "    #print (x)\n",
    "    if isinstance(x[\"age\"],int) and 0<(x[\"age\"])<120:\n",
    "        if isinstance(x[\"email\"],str):\n",
    "            x['name'] = x['name'].capitalize()\n",
    "            #print(x)\n",
    "            valid_data.append(x)\n",
    "        \n",
    "print(valid_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aaa5c36b-4134-4892-a12c-57d0c36afbec",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "788a0636-7601-4740-ac3b-6c963c9ffe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age            email\n",
      "name                      \n",
      "Alice  30  alice@email.com\n",
      "Dave   40   dave@email.com\n"
     ]
    }
   ],
   "source": [
    "# Your answers\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(sample_data)\n",
    "\n",
    "df.set_index('name',inplace=True)\n",
    "\n",
    "age_valid = df['age'].apply(lambda x: True if isinstance(x, int) and 0<= x<=120 else False)\n",
    "email_valid = df['email'].apply(lambda x: True if x!='' else False)   \n",
    "filtered_data = df[age_valid & email_valid]\n",
    "filtered_data.set_index(filtered_data.index.str.capitalize(),inplace=True)\n",
    "print(filtered_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f4490ad-e815-4971-bec7-ed74926afacc",
   "metadata": {},
   "source": [
    "### Part C\n",
    "I wil use a library called email-validator and use the function: validate_email, and EmailNotValidError. This can validate the email and return the normalized format."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9113a85-fe9e-4aa5-b633-d520c2f73a69",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part D\n",
    "Your comments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d95a5fd4-9b6b-41de-8c6c-fadbc2f7e47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Alice', 'age': 30, 'email': 'alice@email.com'}, {'name': 'Dave', 'age': 40, 'email': 'dave@email.com'}]\n",
      "    name age            email\n",
      "0  Alice  30  alice@email.com\n",
      "3   Dave  40   dave@email.com\n",
      "[{'name': 'Alice', 'age': 30, 'email': 'alice@email.com'}, {'name': 'Dave', 'age': 40, 'email': 'dave@email.com'}]\n",
      "    name age            email\n",
      "0  Alice  30  alice@email.com\n",
      "3   Dave  40   dave@email.com\n"
     ]
    }
   ],
   "source": [
    "# Any necessary code here\n",
    "# AI's code:\n",
    "# Part A\n",
    "sample_data = [\n",
    "    {\"name\": \"alice\", \"age\": 30, \"email\": \"alice@email.com\"},\n",
    "    {\"name\": \"bob\", \"age\": \"not_an_age\", \"email\": \"bob@email.com\"},\n",
    "    {\"name\": \"carol\", \"age\": 150, \"email\": \"\"},\n",
    "    {\"name\": \"dave\", \"age\": 40, \"email\": \"dave@email.com\"}\n",
    "]\n",
    "\n",
    "def clean_data(data):\n",
    "    cleaned = []\n",
    "    for record in data:\n",
    "        age = record.get(\"age\")\n",
    "        email = record.get(\"email\")\n",
    "        name = record.get(\"name\").capitalize()\n",
    "        if isinstance(age, (int, float)) and 0 <= age <= 120 and email:\n",
    "            cleaned.append({\"name\": name, \"age\": age, \"email\": email})\n",
    "    return cleaned\n",
    "\n",
    "cleaned_data = clean_data(sample_data)\n",
    "print(cleaned_data)\n",
    "#Pros of AI's Approach:\n",
    "#Safety: The AI's solution uses .get() which would return None if a key is missing, preventing potential KeyErrors.\n",
    "#Generality: The AI checks for both integer and float ages.\n",
    "\n",
    "#Cons of AI's Approach:\n",
    "#Additional Function: The AI introduces an extra function, which might be seen as unnecessary overhead for a simple task. Your direct approach without a function is more straightforward.\n",
    "\n",
    "# Part B \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(sample_data)\n",
    "\n",
    "# Remove rows with invalid ages\n",
    "df = df[df['age'].apply(lambda x: isinstance(x, (int, float)) and 0 <= x <= 120)]\n",
    "\n",
    "# Remove rows with empty email\n",
    "df = df[df['email'] != \"\"]\n",
    "\n",
    "# Standardize names\n",
    "df['name'] = df['name'].str.capitalize()\n",
    "\n",
    "print(df)\n",
    "\n",
    "#Comparison:\n",
    "#Pros of AI's Approach:\n",
    "#Flexibility: The AI doesn't set the name as the DataFrame's index. This retains the original structure of the DataFrame and allows for more flexibility in further data operations.\n",
    "#Efficiency: The AI's approach employs pandas' built-in functions in a more chained manner. This can be more efficient, especially with larger datasets.\n",
    "\n",
    "#Cons of AI's Approach:\n",
    "#Clarity: The AI's method of chaining operations may be less readable to some, especially those not deeply familiar with pandas. Your approach with separate validity masks is more verbose but might be clearer to some readers.\n",
    "#No Index Usage: By not using indices (like you did with names), the AI's solution might not leverage potential benefits of pandas indexing, such as faster lookups. However, setting names as indices might not always be desirable, especially if names aren't unique."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ad3e477-3896-490a-aa81-40343f75172f",
   "metadata": {},
   "source": [
    "## Problem 2: Advanced List Slicing with Named Indices\n",
    "* **Part A**: You are given a list of tuples, where each tuple contains a restaurant name and its average meal cost (in dollars). Write a function that returns another list containing the average meal costs of restaurants whose names contain the word \"Chicken\".\n",
    "\n",
    "* **Part B**: Convert the list of tuples into a pandas Series where the index is the restaurant name. Use pandas to perform the slicing based on restaurant names containing the word \"Chicken\".\n",
    "\n",
    "* **Part C**: Reflect on how the transition from implicit indices (in lists) to explicit, named indices (in pandas Series) affects your data manipulation capabilities.\n",
    "\n",
    "* **Part D**: (Follow the general Part D instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7144aef8-bd47-4250-8bd4-c217a5315519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic dataset\n",
    "restaurant_data = [(\"Chicken Palace\", 25),\n",
    "                   (\"Hattie B's Hot Chicken\", 15),\n",
    "                   (\"Vegan Corner\", 20),\n",
    "                   (\"The Wild Cow\", 14),\n",
    "                   (\"Prince's Chicken\", 18),\n",
    "                   (\"Amerigos Italian Restaurant\", 30)]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c820d7d-b993-4c4c-9233-2eb1a28973d0",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eadaf9d7-b243-4c37-84bf-66bb4f93bfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 15, 18]\n"
     ]
    }
   ],
   "source": [
    "# Your answers\n",
    "new_list_cost_chicken = []\n",
    "for index in range(len(restaurant_data)):\n",
    "    if \"Chicken\" in restaurant_data [index][0]:\n",
    "        new_list_cost_chicken.append(restaurant_data[index][1])\n",
    "print(new_list_cost_chicken)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "340c8e1b-26a4-4483-ad0c-2ca1cc39245e",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ec1ffb4-2ac0-4471-8668-c8cbf1746e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicken Palace            25\n",
      "Hattie B's Hot Chicken    15\n",
      "Prince's Chicken          18\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Your answers\n",
    "import pandas as pd\n",
    "list_a = []\n",
    "for el in range(len(restaurant_data)):\n",
    "    list_a.append(restaurant_data[el][0])\n",
    "\n",
    "list_b = []\n",
    "for el in range(len(restaurant_data)):\n",
    "    list_b.append(restaurant_data[el][1])\n",
    "\n",
    "series = pd.Series (list_b, list_a)\n",
    "chicken_or_not= series.index.str.contains('Chicken')\n",
    "filtered_series = series[chicken_or_not]\n",
    "print(filtered_series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "448d7920-88af-4a32-ac59-655daf54b467",
   "metadata": {},
   "source": [
    "### Part C\n",
    "I think the explicit indices are more reader friendly since they can reduce the cognitive load for analysists to filter and analyze data, thus reducing the possibilities of errors.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4d1fd76-8e91-4541-a7f8-c81aa25c8d10",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part D\n",
    "Your comments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9841a65b-0709-48bc-86fc-8b56f8145356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 15, 18]\n",
      "Chicken Palace            25\n",
      "Hattie B's Hot Chicken    15\n",
      "Prince's Chicken          18\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# AI- part A\n",
    "def avg_cost_chicken(restaurants):\n",
    "    return [cost for name, cost in restaurants if \"Chicken\" in name]\n",
    "\n",
    "chicken_costs = avg_cost_chicken(restaurant_data)\n",
    "print(chicken_costs)\n",
    "\n",
    "#Pros of AI's Approach Over Yours:\n",
    "#Conciseness: AI's approach uses list comprehension, which is more concise and typically faster.\n",
    "#Direct Tuple Unpacking: The AI's code directly unpacks the tuple into name and cost, making it clearer which part of the data is being checked and appended.\n",
    "\n",
    "#Cons of AI's Approach Compared to Yours:\n",
    "#Readability: List comprehensions, while concise, may be less readable to some developers compared to traditional for-loops.\n",
    "\n",
    "\n",
    "# AI- part B\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the list of tuples to a pandas Series\n",
    "restaurant_series = pd.Series(dict(restaurant_data))\n",
    "\n",
    "# Slice the series based on index names containing the word \"Chicken\"\n",
    "chicken_costs_series = restaurant_series[restaurant_series.index.str.contains(\"Chicken\")]\n",
    "\n",
    "print(chicken_costs_series)\n",
    "\n",
    "#Pros of AI's Approach Over Yours:\n",
    "#Efficiency: The AI's method avoids creating two separate lists and uses the existing structure of the restaurant_data for Series conversion. This is more memory efficient.\n",
    "#Conciseness: By chaining operations and utilizing pandas functionalities, the AI's code is more concise.\n",
    "#Simpler Series Creation: The AI directly creates a pandas Series from the list of tuples, leveraging the dictionary-like structure of the data. Your approach of splitting the data first before creating the Series is an additional step.\n",
    "\n",
    "#Cons of AI's Approach Compared to Yours:\n",
    "#Potential Complexity: For those unfamiliar with pandas, the AI's chained operations might seem complex. The verbosity of your code could be beneficial for someone new to the library."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3485995a-9ecb-4b43-80c1-ad2c4b7d7ef1",
   "metadata": {},
   "source": [
    "## Problem 3: Weather Data Aggregator\n",
    "* **Part A**: You are given a list of dictionaries, where each dictionary represents weather data for a given city on a specific day. Aggregate this data to find the average, maximum, and minimum temperatures for each city.\n",
    "* **Part B**: Convert the list of dictionaries to a pandas DataFrame and perform the same operation using pandas functionalities.\n",
    "* **Part C**: How could you modify your program to handle missing data?\n",
    "* **Part D**: (Follow the general Part D instructions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc864089-962a-40fd-8a19-d8f3c5640fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic dataset\n",
    "weather_data = {\n",
    "    'New York': [72, 75, 71, 73, 69, 74, 76, 70, 77, 68, 71, 73, 74, 72, 70, 71, 75, 73, 74, 76, 70, 77, 68, 72, 71, 73, 74, 76, 75, 70],\n",
    "    'San Francisco': [62, 63, 65, 64, 61, 63, 65, 60, 62, 61, 64, 66, 63, 64, 65, 63, 61, 62, 66, 64, 63, 62, 64, 66, 61, 62, 65, 64, 63, 61],\n",
    "    'Chicago': [68, 70, 67, 66, 71, 69, 68, 70, 67, 72, 70, 68, 69, 71, 70, 69, 68, 66, 71, 67, 69, 70, 68, 72, 71, 70, 67, 69, 68, 71],\n",
    "    'Miami': [85, 86, 84, 83, 85, 84, 86, 85, 87, 83, 84, 85, 86, 87, 84, 83, 85, 86, 84, 87, 85, 86, 84, 85, 87, 86, 85, 84, 83, 87]\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4d3d166-5b77-4612-9c6f-8136ffdeadbd",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a7800ef-05d2-49b8-a079-190d5a1f0d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average temperature for New York is 72.66666666666667.\n",
      "Maximum temperature for New York is 77.\n",
      "Minimum temperature for New York is 68.\n",
      "Average temperature for San Francisco is 63.166666666666664.\n",
      "Maximum temperature for San Francisco is 66.\n",
      "Minimum temperature for San Francisco is 60.\n",
      "Average temperature for Chicago is 69.06666666666666.\n",
      "Maximum temperature for Chicago is 72.\n",
      "Minimum temperature for Chicago is 66.\n",
      "Average temperature for Miami is 85.03333333333333.\n",
      "Maximum temperature for Miami is 87.\n",
      "Minimum temperature for Miami is 83.\n"
     ]
    }
   ],
   "source": [
    "# Your answers\n",
    "import statistics \n",
    "for keys in weather_data:\n",
    "    print(f\"Average temperature for {keys} is {statistics.mean(weather_data[keys])}.\") #average \n",
    "    print(f\"Maximum temperature for {keys} is {max(weather_data[keys])}.\") #max\n",
    "    print(f\"Minimum temperature for {keys} is {min(weather_data[keys])}.\")#min\n",
    "   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bde8d89-dcfe-430b-8612-963b52267fd4",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5f4ebcf-0cee-4fcf-9110-63ed148f60c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum temperatue for New York is 77.\n",
      "Minimum temperatue for New York is 68.\n",
      "Average temperatue for New York is 72.66666666666667.\n",
      "Maximum temperatue for San Francisco is 66.\n",
      "Minimum temperatue for San Francisco is 60.\n",
      "Average temperatue for San Francisco is 63.166666666666664.\n",
      "Maximum temperatue for Chicago is 72.\n",
      "Minimum temperatue for Chicago is 66.\n",
      "Average temperatue for Chicago is 69.06666666666666.\n",
      "Maximum temperatue for Miami is 87.\n",
      "Minimum temperatue for Miami is 83.\n",
      "Average temperatue for Miami is 85.03333333333333.\n"
     ]
    }
   ],
   "source": [
    "# Your answers\n",
    "import pandas as py\n",
    "df = py.DataFrame(weather_data).T\n",
    "#print(df)\n",
    "# list(weather_data.keys())\n",
    "# list(weather_data.keys())[0]- the first key \n",
    "for n in range (df.shape[0]):\n",
    "    print(f\"Maximum temperatue for {list(weather_data.keys())[n]} is {df.iloc[n].max()}.\") # max\n",
    "    print(f\"Minimum temperatue for {list(weather_data.keys())[n]} is {df.iloc[n].min()}.\") # min\n",
    "    print(f\"Average temperatue for {list(weather_data.keys())[n]} is {df.iloc[n].mean()}.\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82d48a60-0d86-49ff-b625-7daf50ed412c",
   "metadata": {},
   "source": [
    "### Part C\n",
    "I will put the average number of that city to replace any of its empty data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8878a610-4f5c-4e3a-ba08-95d442007252",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part D\n",
    "Your comments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "288020a7-be3a-45ca-9a6c-7fac8dfff22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York {'Average': 72.66666666666667, 'Maximum': 77, 'Minimum': 68}\n",
      "San Francisco {'Average': 63.166666666666664, 'Maximum': 66, 'Minimum': 60}\n",
      "Chicago {'Average': 69.06666666666666, 'Maximum': 72, 'Minimum': 66}\n",
      "Miami {'Average': 85.03333333333333, 'Maximum': 87, 'Minimum': 83}\n",
      "                    mean   max   min\n",
      "New York       72.666667  77.0  68.0\n",
      "San Francisco  63.166667  66.0  60.0\n",
      "Chicago        69.066667  72.0  66.0\n",
      "Miami          85.033333  87.0  83.0\n"
     ]
    }
   ],
   "source": [
    "# AI for Part A\n",
    "def aggregate_weather_data(data):\n",
    "    aggregated_data = {}\n",
    "\n",
    "    for city, temps in data.items():\n",
    "        avg_temp = sum(temps) / len(temps)\n",
    "        max_temp = max(temps)\n",
    "        min_temp = min(temps)\n",
    "\n",
    "        aggregated_data[city] = {\n",
    "            \"Average\": avg_temp,\n",
    "            \"Maximum\": max_temp,\n",
    "            \"Minimum\": min_temp\n",
    "        }\n",
    "\n",
    "    return aggregated_data\n",
    "\n",
    "weather_summary = aggregate_weather_data(weather_data)\n",
    "for city, summary in weather_summary.items():\n",
    "    print(city, summary)\n",
    "    \n",
    "# pros:\n",
    "# Modularity: The AI's code defines a function (aggregate_weather_data) which returns aggregated data. This makes it reusable and keeps the global scope clean.\n",
    "# Custom Aggregation Storage: The AI's method stores aggregated results in a dictionary, making it accessible for future operations if necessary\n",
    "\n",
    "# cons\n",
    "# Verbosity: The AI's solution might appear more verbose due to the function definition and extra dictionary storage.\n",
    "# Direct Calculation: While both methods work efficiently, using statistics.mean() might seem more readable to some.\n",
    "\n",
    "# AI for Part B\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(weather_data)\n",
    "\n",
    "# Use built-in aggregation methods to find average, max, and min temperatures\n",
    "aggregated_df = df.agg([\"mean\", \"max\", \"min\"]).transpose()\n",
    "\n",
    "print(aggregated_df)\n",
    "\n",
    "#pros:\n",
    "#Efficiency: The AI's method leverages pandas' built-in aggregation functions directly on the DataFrame, which are optimized for performance and conciseness.\n",
    "#Conciseness: The AI’s code is more concise since it avoids looping over rows. Instead, it applies aggregation directly.\n",
    "#Intuitive Structure: Keeping cities as columns can be more intuitive since each city's data is treated as a feature.\n",
    "\n",
    "#cons:\n",
    "#Direct Printing: Your method prints the aggregated results directly while iterating, which might seem more direct and less abstracted than the AI's approach."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25421eb4-44ca-4b21-ada0-a2e51ab3d0ba",
   "metadata": {},
   "source": [
    "## Problem 4: Class Enrollment\n",
    "* **Part A**: You are given a list of student names and the courses they've enrolled in. Calculate the number of students enrolled in each course.\n",
    "\n",
    "* **Part B**: Convert the list of student-course pairs to a pandas DataFrame and solve the problem using pandas functionalities.\n",
    "\n",
    "* **Part C**: How could the program be extended to also handle scheduling conflicts for enrolled students?\n",
    "\n",
    "* **Part D**: (Follow the general Part D instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14bd9736-d32a-4164-84d0-f6622f142fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic dataset\n",
    "enrollments = [(\"Alice\", \"Math\"), (\"Bob\", \"Physics\"),\n",
    "               (\"Alice\", \"Physics\"), (\"Carol\", \"Math\"),\n",
    "               (\"Dave\", \"Biology\")]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8963e9f-fbe7-47b7-b7d3-28884d62daeb",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "697f50ba-774f-47d9-8766-109c5a0b8c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Math': 2, 'Physics': 2, 'Biology': 1}\n"
     ]
    }
   ],
   "source": [
    "# Your answers\n",
    "course_counts = {}\n",
    "for _,course in enrollments:\n",
    "    #print(course)\n",
    "    if course in course_counts:\n",
    "        course_counts[course] +=1\n",
    "    else:\n",
    "        course_counts [course]=1\n",
    "print(course_counts)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cadd9bb-9a80-4c33-852d-f7ae41815963",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "64b0ca70-9ed4-4d50-baa3-e16fd5db8548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0        1\n",
      "0  Alice     Math\n",
      "1    Bob  Physics\n",
      "2  Alice  Physics\n",
      "3  Carol     Math\n",
      "4   Dave  Biology\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biology</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Math</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physics</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "1         \n",
       "Biology  1\n",
       "Math     2\n",
       "Physics  2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answers\n",
    "import pandas as py\n",
    "df = py.DataFrame(enrollments)\n",
    "print(df)\n",
    "df.groupby(df[1]).count()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0273b8bc-9843-4d1f-94de-0d0f6862e0f9",
   "metadata": {},
   "source": [
    "### Part C\n",
    "I can input the schedule for every student's enrolled class. Then I can group the students and check whether they have same schedules for their classes. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b434a76c-7d2e-4530-b982-77298423c5ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part D\n",
    "Your comments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fef97417-5fc8-4287-896c-ec08179c0f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Math': 2, 'Physics': 2, 'Biology': 1}\n",
      "Course\n",
      "Biology    1\n",
      "Math       2\n",
      "Physics    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# AI for part A\n",
    "enrollments = [(\"Alice\", \"Math\"), (\"Bob\", \"Physics\"),\n",
    "               (\"Alice\", \"Physics\"), (\"Carol\", \"Math\"),\n",
    "               (\"Dave\", \"Biology\")]\n",
    "\n",
    "course_counts = {}\n",
    "\n",
    "for _, course in enrollments:\n",
    "    if course in course_counts:\n",
    "        course_counts[course] += 1\n",
    "    else:\n",
    "        course_counts[course] = 1\n",
    "\n",
    "print(course_counts)\n",
    "\n",
    "#Pros\n",
    "#Minimal Difference: In reality, there isn't much of a difference in the logic of the two approaches for Part A. Both solutions use a dictionary to aggregate the counts, making them equally efficient.\n",
    "\n",
    "#Cons\n",
    "#Redundancy: There isn't any distinct advantage of ChatGPT's code over yours for Part A since the solutions are nearly identical.\n",
    "\n",
    "# AI for part B\n",
    "import pandas as pd\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(enrollments, columns=[\"Student\", \"Course\"])\n",
    "\n",
    "# Group by course and count\n",
    "enrollment_counts = df.groupby(\"Course\").size()\n",
    "\n",
    "print(enrollment_counts)\n",
    "\n",
    "#Pros\n",
    "#Column Naming: ChatGPT's approach provides column names (\"Student\" and \"Course\") during DataFrame creation, which makes the DataFrame more readable and makes the subsequent code more self-explanatory.\n",
    "#Standard Alias: The use of pd as an alias for pandas is more conventional in the data science and analytics community.\n",
    "\n",
    "#Cons \n",
    "#Explicitness: If someone isn't familiar with pandas conventions, they might find your approach of using column indices (e.g., df[1]) more explicit in indicating that operations are based on the second column of the DataFrame."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a35f9b75-7835-4a4c-af3e-c2f3288ebefb",
   "metadata": {},
   "source": [
    "## Problem 5: File Search\n",
    "Your task is to write a Python function that takes a directory path and a file extension as input and returns a list of all files with the given extension located within the directory or any of its sub-directories. Use Python's `os` module to accomplish this.\n",
    "\n",
    "Below is an example file tree; however, you can use a custom-created (or already existing) filetree on your own computer. The files of interest should be 2-3 directories deep as shown below.\n",
    "\n",
    "```\n",
    "/\n",
    "|-- home/\n",
    "|   |-- user/\n",
    "|   |   |-- documents/\n",
    "|   |   |   |-- file1.txt\n",
    "|   |   |   `-- file2.pdf\n",
    "|   |   `-- downloads/\n",
    "|   |       `-- music/\n",
    "|   |           |-- song1.mp3\n",
    "|   |           `-- song2.mp3\n",
    "`-- var/\n",
    "    `-- tmp/\n",
    "        |-- file3.txt\n",
    "        `-- file4.pdf\n",
    "\n",
    "```\n",
    "\n",
    "* **Part A**: Using only Python's built-in os module, write your function. Assume that the directory tree is represented as a list of strings following a specific structure.\n",
    "* **Part B**: Perform the same operation using a different Python package (e.g., `glob`) or a different approach (e.g., recursion).\n",
    "* **Part D**: Use generative AI to come up with a different approach for solving this problem, and evaluate your two solutions against the AI's. Note down any insights or advantages you discover in the process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19e8a15e-8ad3-4806-84f0-a1f345538f64",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "42a0b984-8992-47a2-9048-626e7f7517bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Your answers\n",
    "import os\n",
    "\n",
    "def scan_files(directory, extension):\n",
    "    root = os.path.abspath(directory)\n",
    "    \n",
    "    list_sub_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(root,topdown=True):\n",
    "        for file in files:\n",
    "            if file.endswith(extension):\n",
    "                list_sub_files.append(os.path.join(root,file))\n",
    "                    \n",
    "    print(list_sub_files)\n",
    "  \n",
    "def main():\n",
    "    directory = \"/Users/chenhanlin/Documents/vandy 23 fall/AI-programming/Assignment\"\n",
    "    scan_files(directory, '.pdf')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57c649fa-8562-4bd0-839c-ef606531f132",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4406b56a-27aa-48b2-b212-3f6b43495eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Your answers\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def scan_files(directory, extension):\n",
    "    list_sub_files=[]\n",
    "    for filename in glob.iglob(os.path.join(directory,'**',('*'+ extension)),recursive = True):\n",
    "       list_sub_files.append(filename)\n",
    "    print(list_sub_files)\n",
    "        \n",
    "\n",
    "def main():\n",
    "    directory = \"/Users/chenhanlin/Documents/vandy 23 fall/AI-programming/Assignment\"\n",
    "    scan_files(directory, '.pdf')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8459091a-cc77-474b-9627-b14648d2230e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part D\n",
    "Your comments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e65e18-c188-42f5-a171-cbcdfc64ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI for Part A\n",
    "import os\n",
    "\n",
    "def find_files_with_extension(directory, extension):\n",
    "    matching_files = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(extension):\n",
    "                matching_files.append(os.path.join(dirpath, filename))\n",
    "\n",
    "    return matching_files\n",
    "\n",
    "#For the above example file tree, if you want to get all .txt files:\n",
    "print(find_files_with_extension('/path_to_root_directory', '.txt'))\n",
    "\n",
    "'''Pros:\n",
    "Clear, straightforward logic using os.walk().\n",
    "Uses a list comprehension approach, which can be more concise for this type of operation.\n",
    "Returns the list of files, offering more flexibility and allowing for potential additional processing or usage.\n",
    "\n",
    "Cons:\n",
    "Does not use os.path.abspath(directory), so if a relative path is provided, it depends on the current working directory.'''\n",
    "\n",
    "# AI for Part B\n",
    "import glob\n",
    "\n",
    "def find_files_with_glob(directory, extension):\n",
    "    # ** will search in all directories and subdirectories\n",
    "    return glob.glob(f\"{directory}/**/*{extension}\", recursive=True)\n",
    "\n",
    "print(find_files_with_glob('/path_to_root_directory', '.txt'))\n",
    "# ['/path_to_root_directory/home/user/documents/file1.txt', '/path_to_root_directory/var/tmp/file3.txt']\n",
    "'''Pros:\n",
    "Efficient usage of glob.glob() to search for files with the desired extension.\n",
    "Returns the list of files, offering more flexibility.\n",
    "\n",
    "Cons:\n",
    "Does not directly handle edge cases, such as if an incorrect path is provided.'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb34228d-6137-4bd4-b05f-23d91c4ddcdd",
   "metadata": {},
   "source": [
    "## Problem 6: Time-Series Data Transformation for Plotting\n",
    "* **Part A**: You are given two lists: one containing timestamps and another containing corresponding temperature readings. Generate a list of (timestamp, temperature) pairs.\n",
    "\n",
    "* **Part B**: Convert the two lists into a single pandas DataFrame and perform the same operation using pandas functionalities.\n",
    "\n",
    "* **Part C**: Suppose you had to extend the functionality to also annotate significant events in the data, how might you incorporate this into your existing solutions?\n",
    "\n",
    "* **Part D**: (Follow the general Part D instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "afaf63c9-6c09-4abd-8b86-3f7ae5940f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic dataset\n",
    "timestamps = [0, 3600, 7200, 4800]\n",
    "temperatures = [20, 21, 19, 23]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14e1a6a9-73b3-4a4f-8719-0a3387469ece",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b3d32a7f-0089-4586-9ba4-560535a2eb1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timestamps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Your answers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#del list if needed \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(timestamps,temperatures)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timestamps' is not defined"
     ]
    }
   ],
   "source": [
    "# Your answers\n",
    "#del list if needed \n",
    "print(list(zip(timestamps,temperatures)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94d7240d-86c2-4c9d-a19a-89762b4d4f9f",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a9c113ab-c4af-415c-a568-1b0d2c30b534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            temperatures\n",
      "timestamps              \n",
      "0                     20\n",
      "3600                  21\n",
      "7200                  19\n",
      "4800                  23\n"
     ]
    }
   ],
   "source": [
    "# Your answers\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'timestamps':timestamps,'temperatures':temperatures})\n",
    "df.set_index('timestamps',inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4f1f691-5698-49d2-9e9d-1b761eb3dcc7",
   "metadata": {},
   "source": [
    "### Part C\n",
    "I will add another column which is called significance. I will label one if the record is significant. So I can count how many records are of significance. I can also see when these significant events happen. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66288ad8-1322-45aa-aad9-94ac6d17e2a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part D\n",
    "Your comments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "052d2156-d0ba-4f4e-b140-33851844c189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 20), (3600, 21), (7200, 19), (4800, 23)]\n",
      "   Timestamp  Temperature\n",
      "0          0           20\n",
      "1       3600           21\n",
      "2       7200           19\n",
      "3       4800           23\n"
     ]
    }
   ],
   "source": [
    "# AI for part A\n",
    "data_pairs = list(zip(timestamps, temperatures))\n",
    "print(data_pairs)\n",
    "\n",
    "#pros\n",
    "#Indexing: By setting timestamps as the index, you have made time-series analysis easier. Pandas is specifically designed to handle time-series data efficiently when timestamps are set as indices.\n",
    "#Data Visualization: If you wanted to plot the data using tools that recognize pandas DataFrames (like Seaborn), your indexed DataFrame would be more immediately ready for many types of plots.\n",
    "\n",
    "#cons\n",
    "#Flexibility: Since you set the timestamps as indices, any further data manipulations would need to be mindful of the indexed structure, which can be restrictive for certain operations.\n",
    "#Data Addition: If you wanted to add more columns to the DataFrame later, you would have to reset the index or work with multi-index structures.\n",
    "\n",
    "# AI for part B\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Timestamp': timestamps, 'Temperature': temperatures})\n",
    "print(df)\n",
    "\n",
    "#pros\n",
    "#Simplicity: The AI's approach keeps the data in a simple tabular form, which might be more intuitive for users unfamiliar with time-series data in pandas.\n",
    "#General Usability: For general tasks that don't require time-series functions, having timestamps as a regular column can sometimes be more straightforward.\n",
    "\n",
    "#cons\n",
    "#Time-Series Analysis: Without setting the timestamps as an index, leveraging some of pandas' powerful time-series functions would require an extra step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
